{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad7e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from src.envs.make_env import make_env, make_vec_env\n",
    "from src.agents.stochastic_agent import StochasticAgent\n",
    "from src.networks.policy_network import PolicyNetwork, ValueNetwork\n",
    "from src.training.REINFORCE_trainer import Trainer as REINFORCETrainer\n",
    "from src.training.A2C_trainer import Trainer as A2CTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb2fe3",
   "metadata": {},
   "source": [
    "## Hyperparameters Configuration\n",
    "\n",
    "Modify these values to tune the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526255b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ MODEL SELECTION ============\n",
    "model_type = \"A2C\"  # Options: \"REINFORCE\", \"A2C\"\n",
    "\n",
    "# ============ TRAINING HYPERPARAMETERS ============\n",
    "# Environment\n",
    "num_episodes = 3000  # Total number of training episodes (for REINFORCE) or total steps / avg_ep_len (for A2C)\n",
    "log_interval = 20  # Print stats every N episodes\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.0025  # Actor learning rate (policy network)\n",
    "gamma = 0.99  # Discount factor\n",
    "\n",
    "# Baseline (REINFORCE with baseline for variance reduction)\n",
    "baseline = False  # Only used for REINFORCE\n",
    "value_learning_rate = 0.005  # Learning rate for value/critic network\n",
    "\n",
    "# ============ A2C SPECIFIC HYPERPARAMETERS ============\n",
    "n_envs = 8  # Number of parallel environments\n",
    "n_steps = 5  # N-step returns for advantage calculation\n",
    "train_every = 4  # Update networks every N steps (batch from steps 0, 4, 8...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167744d",
   "metadata": {},
   "source": [
    "## Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b672eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”µ Using A2C Trainer (N-step Advantage Actor-Critic)\n",
      "   ðŸ“Š Parallel environments: 8\n",
      "   ðŸ“Š N-step returns: 5\n",
      "   ðŸ“Š Train every: 4 steps\n",
      "   ðŸ“Š Target episodes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "# Initialize Policy Network\n",
    "policy_network = PolicyNetwork(input_size=8, output_size=4)\n",
    "\n",
    "# Initialize Value Network (for baseline in REINFORCE or critic in Actor-Critic)\n",
    "use_value_network = baseline or model_type == \"A2C\"\n",
    "value_network = ValueNetwork(input_size=8) if use_value_network else None\n",
    "\n",
    "# Initialize trainer based on model_type\n",
    "if model_type == \"REINFORCE\":\n",
    "    # Initialize agent (only for REINFORCE single-env training)\n",
    "    agent = StochasticAgent(action_space=4, policy_network=policy_network)\n",
    "    \n",
    "    trainer = REINFORCETrainer(\n",
    "        policy_network, \n",
    "        learning_rate=learning_rate, \n",
    "        gamma=gamma,\n",
    "        baseline=baseline,\n",
    "        value_network=value_network,\n",
    "        value_learning_rate=value_learning_rate\n",
    "    )\n",
    "    # Create single environment\n",
    "    env = make_env(render_mode=\"rgb_array\")\n",
    "    \n",
    "    if baseline:\n",
    "        print(f\"ðŸŸ£ Using REINFORCE Trainer with Baseline (Policy Gradient + Value Network)\")\n",
    "    else:\n",
    "        print(f\"ðŸŸ£ Using REINFORCE Trainer (Policy Gradient)\")\n",
    "\n",
    "elif model_type == \"A2C\":\n",
    "    if value_network is None:\n",
    "        raise ValueError(\"A2C requires a value network\")\n",
    "    \n",
    "    trainer = A2CTrainer(\n",
    "        policy_network=policy_network,\n",
    "        value_network=value_network,\n",
    "        actor_learning_rate=learning_rate,\n",
    "        critic_learning_rate=value_learning_rate,\n",
    "        gamma=gamma,\n",
    "        n_steps=n_steps,\n",
    "        train_every=train_every,\n",
    "        n_envs=n_envs\n",
    "    )\n",
    "    # Create vectorized parallel environments\n",
    "    env = make_vec_env(n_envs=n_envs, render_mode=None)\n",
    "    \n",
    "    print(f\"ðŸ”µ Using A2C Trainer (N-step Advantage Actor-Critic)\")\n",
    "    print(f\"   ðŸ“Š Parallel environments: {n_envs}\")\n",
    "    print(f\"   ðŸ“Š N-step returns: {n_steps}\")\n",
    "    print(f\"   ðŸ“Š Train every: {train_every} steps\")\n",
    "    print(f\"   ðŸ“Š Target episodes: {num_episodes}\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model_type: {model_type}. Use 'REINFORCE' or 'A2C'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45650a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Last run_id found: 27\n",
      "ðŸ†• New run_id: 28\n",
      "âœ… Config appended to runs/all_configs_combined.csv\n",
      "ðŸ“ Log file created: runs/sample_runs_list/run28.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.training.episode_outcome import categorize_episode_outcome, get_outcome_icon\n",
    "\n",
    "# ===== AUTO-INCREMENT RUN ID =====\n",
    "configs_file = 'runs/all_configs_combined.csv'\n",
    "runs_file = 'runs/all_runs_combined.csv'\n",
    "\n",
    "# Read existing configs to find last run_id\n",
    "df_configs = pd.read_csv(configs_file, dtype={'run_id': str})\n",
    "last_run_id = df_configs['run_id'].astype(int).max()\n",
    "new_run_id = str(last_run_id + 1).zfill(2)\n",
    "\n",
    "print(f\"ðŸ“‹ Last run_id found: {last_run_id:02d}\")\n",
    "print(f\"ðŸ†• New run_id: {new_run_id}\")\n",
    "\n",
    "# ===== APPEND NEW CONFIG TO all_configs_combined.csv =====\n",
    "# Policy gradient methods use different hyperparameters - fill DQN-specific ones with NA\n",
    "new_config = {\n",
    "    'run_id': new_run_id,\n",
    "    'model_type': model_type,\n",
    "    'num_episodes': num_episodes,\n",
    "    'log_interval': log_interval,\n",
    "    'train_every': train_every if model_type == 'A2C' else 'NA',\n",
    "    'batch_size': n_envs if model_type == 'A2C' else 'NA',\n",
    "    'learning_rate': learning_rate,\n",
    "    'gamma': gamma,\n",
    "    'update_mode': 'NA',  # Not used in policy gradient methods\n",
    "    'tau': 'NA',  # Not used in policy gradient methods\n",
    "    'target_update_freq': 'NA',  # Not used in policy gradient methods\n",
    "    'replay_buffer_size': 'NA',  # Not used in policy gradient methods\n",
    "    'epsilon_starting_value': 'NA',  # Not used in policy gradient methods\n",
    "    'epsilon_ending_value': 'NA',  # Not used in policy gradient methods\n",
    "    'epsilon_decay_value': 'NA',  # Not used in policy gradient methods\n",
    "    'baseline': baseline if model_type == 'REINFORCE' else 'NA',\n",
    "    'value_lr': value_learning_rate if (baseline or model_type == 'A2C') else 'NA',\n",
    "    'n_steps': n_steps if model_type == 'A2C' else 'NA',\n",
    "    'n_envs': n_envs if model_type == 'A2C' else 'NA'\n",
    "}\n",
    "\n",
    "# Append to configs file\n",
    "new_config_df = pd.DataFrame([new_config])\n",
    "new_config_df.to_csv(configs_file, mode='a', header=False, index=False)\n",
    "print(f\"âœ… Config appended to {configs_file}\")\n",
    "\n",
    "# ===== SETUP LOG FILE =====\n",
    "run_list_dir = 'runs/sample_runs_list'\n",
    "os.makedirs(run_list_dir, exist_ok=True)\n",
    "log_file = f'{run_list_dir}/run{new_run_id}.csv'\n",
    "\n",
    "with open(log_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['episode', 'reward', 'length', 'terminated', 'truncated', 'outcome'])\n",
    "\n",
    "print(f\"ðŸ“ Log file created: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907174b",
   "metadata": {},
   "source": [
    "## Training Loop with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3af04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting A2C training for Run 28...\n",
      "\n",
      "   Target episodes: 5\n",
      "   Environments: 8 parallel\n",
      "   N-step returns: 5\n",
      "   Train every: 4 steps\n",
      "\n",
      "Episode    1 | Env 7 | Steps:   66 | Reward:  -82.87 | ðŸ”´ Crashed\n",
      "Episode    2 | Env 3 | Steps:   71 | Reward: -118.00 | ðŸ”´ Crashed\n",
      "Episode    3 | Env 4 | Steps:   74 | Reward: -179.14 | ðŸ”´ Crashed\n",
      "Episode    4 | Env 0 | Steps:   78 | Reward: -130.75 | ðŸ”´ Crashed\n",
      "Episode    5 | Env 5 | Steps:   87 | Reward:  -86.61 | ðŸ”´ Crashed\n",
      "âœ… Logs appended to runs/all_runs_combined.csv\n",
      "\n",
      "âœ… Training completed for Run 28!\n",
      "Model type: A2C\n",
      "Total episodes: 5\n",
      "Total timesteps: 696\n",
      "\n",
      "ðŸ“Š Episode Outcomes:\n",
      "  ðŸš€ Landed successfully: 0 (0.0%)\n",
      "  ðŸ’¥ Crashed: 5 (100.0%)\n",
      "  ðŸ“ Out of bounds: 0 (0.0%)\n",
      "  â±ï¸  Time limit: 0 (0.0%)\n",
      "\n",
      "ðŸ“ Individual log saved to: runs/sample_runs_list/run28.csv\n",
      "ðŸ“ Combined logs updated: runs/all_runs_combined.csv\n",
      "ðŸ“ Configs updated: runs/all_configs_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Training loop with episode outcome logging\n",
    "episode_rewards = []\n",
    "episode_outcomes = []\n",
    "episode_losses = []\n",
    "episode_logs = []  # Store logs for appending to combined file\n",
    "\n",
    "if model_type == \"REINFORCE\":\n",
    "    # =====================================================\n",
    "    # REINFORCE Training Loop (single environment)\n",
    "    # =====================================================\n",
    "    print(f\"ðŸš€ Starting REINFORCE training for Run {new_run_id}...\\n\")\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        total_reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        episode_length = 0\n",
    "        final_obs = obs\n",
    "        last_step_reward = 0.0\n",
    "        \n",
    "        # Reset episode data in trainer\n",
    "        trainer.reset_episode()\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            # Ask agent for action\n",
    "            action = agent.act(obs)\n",
    "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # Store last step reward (used for outcome classification)\n",
    "            last_step_reward = reward\n",
    "            trainer.store_transition(obs, action, reward)\n",
    "\n",
    "            total_reward += reward\n",
    "            episode_length += 1\n",
    "            obs = next_obs\n",
    "            final_obs = next_obs\n",
    "\n",
    "        # Update policy at end of episode\n",
    "        loss = trainer.train_step()\n",
    "        \n",
    "        episode_rewards.append(total_reward)\n",
    "        episode_losses.append(loss)\n",
    "\n",
    "        # Categorize episode outcome\n",
    "        outcome = categorize_episode_outcome(final_obs, episode_length, last_step_reward)\n",
    "        episode_outcomes.append(outcome)\n",
    "\n",
    "        # Store log entry\n",
    "        log_entry = {\n",
    "            'run_id': new_run_id,\n",
    "            'episode': episode + 1,\n",
    "            'reward': round(total_reward, 2),\n",
    "            'length': episode_length,\n",
    "            'terminated': int(terminated),\n",
    "            'truncated': int(truncated),\n",
    "            'outcome': outcome\n",
    "        }\n",
    "        episode_logs.append(log_entry)\n",
    "\n",
    "        # Log to individual run CSV file\n",
    "        with open(log_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([episode + 1, f\"{total_reward:.2f}\", episode_length,\n",
    "                             int(terminated), int(truncated), outcome])\n",
    "\n",
    "        # Print individual episode result\n",
    "        outcome_icon = get_outcome_icon(outcome)\n",
    "        print(\n",
    "            f\"Episode {episode + 1:4d} | Steps: {episode_length:4d} | Reward: {total_reward:7.2f} | \"\n",
    "            f\"Loss: {loss:7.4f} | {outcome_icon} {outcome.replace('_', ' ').title()}\"\n",
    "        )\n",
    "\n",
    "        # Log average reward every N episodes\n",
    "        if (episode + 1) % log_interval == 0:\n",
    "            avg_reward = sum(episode_rewards[-log_interval:]) / log_interval\n",
    "            avg_loss = sum(episode_losses[-log_interval:]) / log_interval\n",
    "\n",
    "            recent_outcomes = episode_outcomes[-log_interval:]\n",
    "            outcome_counts = {\n",
    "                'success': recent_outcomes.count('landed_success'),\n",
    "                'crashed': recent_outcomes.count('crashed'),\n",
    "                'out_of_bounds': recent_outcomes.count('out_of_bounds'),\n",
    "                'time_limit': recent_outcomes.count('time_limit')\n",
    "            }\n",
    "\n",
    "            print(\n",
    "                f\"  â””â”€ Avg Reward: {avg_reward:7.3f} | Avg Loss: {avg_loss:7.4f} | \"\n",
    "                f\"Success: {outcome_counts['success']}, \"\n",
    "                f\"Crashed: {outcome_counts['crashed']}, \"\n",
    "                f\"Out of bounds: {outcome_counts['out_of_bounds']}, \"\n",
    "                f\"Time limit: {outcome_counts['time_limit']}\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "elif model_type == \"A2C\":\n",
    "    # =====================================================\n",
    "    # A2C Training Loop (parallel environments with n-step)\n",
    "    # =====================================================\n",
    "    print(f\"ðŸš€ Starting A2C training for Run {new_run_id}...\\n\")\n",
    "    print(f\"   Target episodes: {num_episodes}\")\n",
    "    print(f\"   Environments: {n_envs} parallel\")\n",
    "    print(f\"   N-step returns: {n_steps}\")\n",
    "    print(f\"   Train every: {train_every} steps\\n\")\n",
    "    \n",
    "    # Initialize environments\n",
    "    obs, info = env.reset()\n",
    "    episode_count = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    # Track rewards per environment\n",
    "    env_episode_rewards = [0.0 for _ in range(n_envs)]\n",
    "    env_episode_lengths = [0 for _ in range(n_envs)]\n",
    "    env_last_step_rewards = [0.0 for _ in range(n_envs)]\n",
    "    env_final_obs = [obs[i] for i in range(n_envs)]\n",
    "    \n",
    "    while episode_count < num_episodes:\n",
    "        # Select actions for all environments\n",
    "        actions, log_probs, values, _ = trainer.select_actions(obs)\n",
    "        \n",
    "        # Step all environments\n",
    "        next_obs, rewards, terminateds, truncateds, infos = env.step(actions)\n",
    "        dones = np.logical_or(terminateds, truncateds)\n",
    "        \n",
    "        # Store transition\n",
    "        trainer.store_transition(obs, actions, rewards, dones, values, log_probs)\n",
    "        \n",
    "        # Track per-environment episode data\n",
    "        for i in range(n_envs):\n",
    "            env_episode_rewards[i] += rewards[i]\n",
    "            env_episode_lengths[i] += 1\n",
    "            env_last_step_rewards[i] = rewards[i]\n",
    "            env_final_obs[i] = next_obs[i]\n",
    "            \n",
    "            if dones[i]:\n",
    "                # Episode completed for environment i\n",
    "                total_reward = env_episode_rewards[i]\n",
    "                episode_length = env_episode_lengths[i]\n",
    "                final_obs_i = env_final_obs[i]\n",
    "                last_step_reward = env_last_step_rewards[i]\n",
    "                \n",
    "                episode_count += 1\n",
    "                episode_rewards.append(total_reward)\n",
    "                \n",
    "                # Categorize outcome\n",
    "                outcome = categorize_episode_outcome(final_obs_i, episode_length, last_step_reward)\n",
    "                episode_outcomes.append(outcome)\n",
    "                \n",
    "                # Store log entry\n",
    "                log_entry = {\n",
    "                    'run_id': new_run_id,\n",
    "                    'episode': episode_count,\n",
    "                    'reward': round(total_reward, 2),\n",
    "                    'length': episode_length,\n",
    "                    'terminated': int(terminateds[i]),\n",
    "                    'truncated': int(truncateds[i]),\n",
    "                    'outcome': outcome\n",
    "                }\n",
    "                episode_logs.append(log_entry)\n",
    "                \n",
    "                # Log to individual run CSV file\n",
    "                with open(log_file, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([episode_count, f\"{total_reward:.2f}\", episode_length,\n",
    "                                     int(terminateds[i]), int(truncateds[i]), outcome])\n",
    "                \n",
    "                # Reset tracking for this environment\n",
    "                env_episode_rewards[i] = 0.0\n",
    "                env_episode_lengths[i] = 0\n",
    "                \n",
    "                # Print episode result\n",
    "                outcome_icon = get_outcome_icon(outcome)\n",
    "                print(\n",
    "                    f\"Episode {episode_count:4d} | Env {i} | Steps: {episode_length:4d} | \"\n",
    "                    f\"Reward: {total_reward:7.2f} | {outcome_icon} {outcome.replace('_', ' ').title()}\"\n",
    "                )\n",
    "                \n",
    "                # Log average every N episodes\n",
    "                if episode_count % log_interval == 0 and episode_count > 0:\n",
    "                    avg_reward = np.mean(episode_rewards[-log_interval:])\n",
    "                    stats = trainer.get_episode_stats()\n",
    "                    \n",
    "                    recent_outcomes = episode_outcomes[-log_interval:]\n",
    "                    outcome_counts = {\n",
    "                        'success': recent_outcomes.count('landed_success'),\n",
    "                        'crashed': recent_outcomes.count('crashed'),\n",
    "                        'out_of_bounds': recent_outcomes.count('out_of_bounds'),\n",
    "                        'time_limit': recent_outcomes.count('time_limit')\n",
    "                    }\n",
    "                    \n",
    "                    print(\n",
    "                        f\"  â””â”€ Step: {global_step:6d} | Avg Reward: {avg_reward:7.3f} | \"\n",
    "                        f\"Actor Loss: {stats['avg_actor_loss']:.4f} | Critic Loss: {stats['avg_critic_loss']:.4f}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"     Success: {outcome_counts['success']}, Crashed: {outcome_counts['crashed']}, \"\n",
    "                        f\"OOB: {outcome_counts['out_of_bounds']}, Timeout: {outcome_counts['time_limit']}\"\n",
    "                    )\n",
    "                    print()\n",
    "        \n",
    "        # Train step (updates when buffer is full)\n",
    "        train_result = trainer.train_step(next_obs, dones)\n",
    "        if train_result is not None:\n",
    "            episode_losses.append(train_result['actor_loss'])\n",
    "        \n",
    "        obs = next_obs\n",
    "        global_step += n_envs  # Each step processes n_envs transitions\n",
    "\n",
    "env.close()\n",
    "\n",
    "# ===== APPEND LOGS TO all_runs_combined.csv =====\n",
    "logs_df = pd.DataFrame(episode_logs)\n",
    "logs_df.to_csv(runs_file, mode='a', header=False, index=False)\n",
    "print(f\"âœ… Logs appended to {runs_file}\")\n",
    "\n",
    "num_episodes_actual = len(episode_rewards)\n",
    "print(f\"\\nâœ… Training completed for Run {new_run_id}!\")\n",
    "print(f\"Model type: {model_type}\")\n",
    "print(f\"Total episodes: {num_episodes_actual}\")\n",
    "if model_type == \"A2C\":\n",
    "    print(f\"Total timesteps: {global_step}\")\n",
    "\n",
    "# Final statistics\n",
    "success_count = episode_outcomes.count('landed_success')\n",
    "crashed_count = episode_outcomes.count('crashed')\n",
    "out_of_bounds_count = episode_outcomes.count('out_of_bounds')\n",
    "time_limit_count = episode_outcomes.count('time_limit')\n",
    "\n",
    "print(f\"\\nðŸ“Š Episode Outcomes:\")\n",
    "print(f\"  ðŸš€ Landed successfully: {success_count} ({100*success_count/num_episodes_actual:.1f}%)\")\n",
    "print(f\"  ðŸ’¥ Crashed: {crashed_count} ({100*crashed_count/num_episodes_actual:.1f}%)\")\n",
    "print(f\"  ðŸ“ Out of bounds: {out_of_bounds_count} ({100*out_of_bounds_count/num_episodes_actual:.1f}%)\")\n",
    "print(f\"  â±ï¸  Time limit: {time_limit_count} ({100*time_limit_count/num_episodes_actual:.1f}%)\")\n",
    "print(f\"\\nðŸ“ Individual log saved to: {log_file}\")\n",
    "print(f\"ðŸ“ Combined logs updated: {runs_file}\")\n",
    "print(f\"ðŸ“ Configs updated: {configs_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef77c6",
   "metadata": {},
   "source": [
    "## Plot Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f71ba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (0,) and (36,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m window = \u001b[32m40\u001b[39m\n\u001b[32m      9\u001b[39m moving_avg = np.convolve(episode_rewards, np.ones(window)/window, mode=\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepisode_rewards\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoving_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m         \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMoving Avg (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwindow\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m episodes)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mblack\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Color and marker mapping for outcomes\u001b[39;00m\n\u001b[32m     14\u001b[39m outcome_styles = {\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlanded_success\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mcolor\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mLanded Success\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcrashed\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mcolor\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mCrashed\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mout_of_bounds\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mcolor\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33myellow\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m^\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mOut of Bounds\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mcolor\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mTime Limit\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m     19\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (0,) and (36,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot episode rewards over time with outcome colors and different markers\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Base line plot\n",
    "ax.plot(episode_rewards, alpha=0.3, label='Episode Reward', linewidth=1, color='gray')\n",
    "\n",
    "# Plot moving average\n",
    "window = 40\n",
    "moving_avg = np.convolve(episode_rewards, np.ones(window)/window, mode='valid')\n",
    "ax.plot(range(window-1, len(episode_rewards)), moving_avg, linewidth=2.5, \n",
    "         label=f'Moving Avg ({window} episodes)', color='black')\n",
    "\n",
    "# Color and marker mapping for outcomes\n",
    "outcome_styles = {\n",
    "    'landed_success': {'color': 'green', 'marker': 'o', 'label': 'Landed Success'},\n",
    "    'crashed': {'color': 'red', 'marker': 'X', 'label': 'Crashed'},\n",
    "    'out_of_bounds': {'color': 'yellow', 'marker': '^', 'label': 'Out of Bounds'},\n",
    "    'time_limit': {'color': 'blue', 'marker': 's', 'label': 'Time Limit'}\n",
    "}\n",
    "\n",
    "# Plot scatter points with different markers for each outcome\n",
    "for outcome, style in outcome_styles.items():\n",
    "    episodes = [i for i, o in enumerate(episode_outcomes) if o == outcome]\n",
    "    rewards = [episode_rewards[i] for i in episodes]\n",
    "    ax.scatter(episodes, rewards, c=style['color'], marker=style['marker'], \n",
    "              label=style['label'], s=80, alpha=0.7, edgecolors='black', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Episode', fontsize=12)\n",
    "ax.set_ylabel('Total Reward', fontsize=12)\n",
    "ax.set_title('LunarLander REINFORCE - Training Progress by Outcome', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Training Statistics:\")\n",
    "print(f\"  Average Reward: {np.mean(episode_rewards):.3f}\")\n",
    "print(f\"  Max Reward: {np.max(episode_rewards):.3f}\")\n",
    "print(f\"  Min Reward: {np.min(episode_rewards):.3f}\")\n",
    "print(f\"  Std Dev: {np.std(episode_rewards):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7bb81",
   "metadata": {},
   "source": [
    "## Watch Trained Agent in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17393158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\DataScience_Unitn\\Lunar_Lander_Reinforcement_Learning\\videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¬ Trained Agent Performance:\n",
      " Total Reward: 190.198\n",
      " Episode Steps: 395\n",
      " Outcome: ðŸŸ¢ Landed Success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"600\" controls autoplay loop>\n",
       "    <source src=\"videos\\trained_agent_reinforce-episode-0.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "from IPython.display import HTML\n",
    "import glob\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=\"videos\",\n",
    "    episode_trigger=lambda episode_id: True,\n",
    "    name_prefix=\"trained_agent_reinforce\"\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "final_reward = 0.0\n",
    "terminated = False\n",
    "truncated = False\n",
    "episode_steps = 0\n",
    "final_obs = obs\n",
    "last_step_reward = 0.0\n",
    "\n",
    "# Use greedy policy (no sampling, just argmax)\n",
    "while not (terminated or truncated):\n",
    "    # Select best action (deterministic)\n",
    "    with torch.no_grad():\n",
    "        probs = policy_network.predict(obs)\n",
    "        action = torch.argmax(probs, dim=-1).item()\n",
    "    \n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    final_reward += reward\n",
    "    episode_steps += 1\n",
    "    final_obs = obs\n",
    "    last_step_reward = reward\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Categorize episode outcome\n",
    "outcome = categorize_episode_outcome(\n",
    "    final_obs,\n",
    "    episode_steps,\n",
    "    last_step_reward\n",
    ")\n",
    "outcome_icon = get_outcome_icon(outcome)\n",
    "\n",
    "print(f\"\\nðŸŽ¬ Trained Agent Performance:\")\n",
    "print(f\" Total Reward: {final_reward:.3f}\")\n",
    "print(f\" Episode Steps: {episode_steps}\")\n",
    "print(f\" Outcome: {outcome_icon} {outcome.replace('_', ' ').title()}\")\n",
    "\n",
    "# Pick the newest video\n",
    "video_path = max(glob.glob(\"videos/*.mp4\"), key=lambda p: p)\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=\"600\" controls autoplay loop>\n",
    "    <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
